Humam Rashid
CISC 7120X, Fall 2019.

=== PART 1 ===

1. The are many different programming languages because of several reasons:
    a. Many languages evolved from older ones as new programming methodologies,
    syntax, types, etc. were developed.
    b. As new paradigms (e.g., functional, logic, constraint, aspect) and
    application domains (e.g., system administration, AI, web-development) were
    discovered, newer languages were designed around their concepts to ease
    software development.
    b. Personal preference also played a significant role from early on as
    designers preferred certain features that were not available in existing
    languages and some were just designed for fun, for education,
    proof-of-concept and so on.

2. Among the things that make programming languages successful are:
    a. Expressiveness: essentially means being able to write desired algorithms,
    etc. in a relatively easy or intuitive manner.
    b. Availability of implementations: some programming languages have official
    implementations while others have standards/definitions which different
    implementations target their compilers or interpreters toward. Availability
    of good, well-supported implementations is often taken as a key indicator of
    a language's reliability in general.
    c. Efficiency: code in the language needs to run fast enough to get work
    done "quickly." What counts as quick enough can and very often does depend
    on the specific implementation and application domain.
    d. Productivity: programming languages allowing for reduced development time
    and developer ease are often chosen over those with steep development or
    learning time, especially in industry.
    e. Industrial support/sponsorship: languages developed directly by or for
    which development is funded by corporations tend to see wide-spread use,
    often starting with internal use by the sponsoring entity.

3. Reasons for studying programming languages include:
    a. Understanding concepts, features and problem-solving techniques at a
    higher-level. For example, different languages often allow for different
    levels of abstraction or certain built-in data types/structures which allow
    for reasoning about problem solutions in a more intuitive way.
    b. Knowing the different methodologies behind different languages or the
    types of application they are particularly strong in allows for the
    developer to choose "the right tool for the job."
    c. Having knowledge of different languages allows for faster learning of new
    languages in general in a similar fashion to natural languages.
    d. Even if one does not switch to a new language for a task, knowing
    different features or techniques used commonly in other languages allow for
    the possibility to use such techniques where applicable without significant
    shifts in production time.

4. It is important to study the implementation of programming languages to:
    a. Understand how languages are specified and implemented. This also helps
    in learning about different paradigms and their approaches in software
    methodology. Another benefit is that many of the techniques used in design
    and implementation have uses in other areas of computer science research and
    practical software development.
    b. Understanding obscure phenomena. Studying implementation details allows
    us to better prepare and work out problems when unexpected or obscure issues
    show up during development.
    c. Studying language design and implementation allows us to better develop
    or follow well-tested methodologies, style conventions and utilize
    techniques that make programs in the specific language (or other ones) more
    efficient.
    d. Studying design and implementation of programming languages is also the
    primary means of knowing how to design and implement your own language.
    While most people do not need to do this for general-purpose programming, it
    is more often useful in domain-specific tasks.

5. Two languages per paradigm:
    a. Procedural: ALGOL 60, C.
    b. Object-Oriented: Smalltalk, Ruby.
    c. Logic: Prolog, Picat.
    d. Functional: Common Lisp, Standard ML.

6. Features common to object-oriented programming languages include:
    a. Abstract data types.
    b. Inheritance and overriding mechanisms.
    c. Polymorphism.
    d. Dynamic binding.

7. Features common to functional programming languages include:
    a. Single assignment variables and no side-effects (at least in pure
    functional languages).
    b. Recursion (instead of iteration).
    c. Rule-based function definitions and pattern matching.
    d. Higher-order functions.
    e. Lazy evaluation.
    f. Meta-programming.

8. Features common to logic programming languages include:
    a. Logic variables.
    b. Recursion (instead of iteration).
    c. Unification.
    d. Backtracking and non-determinism.
    e. Meta-programming.

=== PART 2 ===

1. Ruby implementation of Trabb Pardo-Knuth algorithm:

puts("Enter 11 numbers: ") or (S = 11.times.map { gets.to_f }).reverse.each { |e| puts ((val = ->x { Math.sqrt(x.abs) + (5 * x) }.call(e)) > 500) ? "f(#{e}): overflow!" : "f(#{e}) = #{val}" }

2. ANSI C implementation of Trabb Pardo-Knuth algorithm:

#include <stdlib.h>
#include <stdio.h>
#include <math.h>
double func(double n) {
    return sqrt(fabs(n)) + (5.0 * n);
}
int main(void)
{
    int e;
    double S[11];
    printf("Enter 11 numbers:\n");
    for (e = 0; e < 11; e++)
        scanf("%lf", &S[e]);
    printf("Result:\n");
    for (e = 10; e >= 0; e--) {
        double val = func(S[e]);
        (val > 500.0)
            ? printf("f(%f) = %s\n", S[e], "caused overflow!")
            : printf("f(%f) = %f\n", S[e], val);
    }
    return EXIT_SUCCESS;
}

=== PART 3 ===

ALSU book exercises.

1. Exercises 1.1.1 on page 3:

    1.1.1) A compiler essentially translates programs from one language into
    another and the final translation is what is utilized by the user or run on
    a machine. Interpreters on the other hand go through a program statement by
    statement, executing each one independently and in sequence.

    1.1.2) a. Compiled programs are generally significantly faster than
           interpreted ones.
           b. Interpreted programs often offer better diagnostic messages which
           makes debugging easier.

    1.1.3) Assembly language is easier for compilers to produce while also being
    easier for programmers to read and debug.

    1.1.4) Using C as a target language offers the advantage of not needing to
    write a separate machine language compiler for the original source language
    and instead being able to use a C compiler to turn the translated C program
    to a native binary.

    1.1.5) An assembler is a language translator that takes input in assembly
    language and produces output in machine language. It essentially takes the
    mnemonics and operations/addresses described in assembly and translates them
    into binary arrangements specific to a processor architecture.

2. Exercise 1.3.3 on page 14:

    1.3.1.1) C -> imperative, von Neumann, third-generation.

    1.3.1.2) C++ -> imperative, von Neumann, object-oriented, functional,
    third-generation.

    1.3.1.3) Cobol -> imperative, von Neumann, object-oriented,
    third-generation.

    1.3.1.4) Fortran -> imperative, von Neumann, object-oriented,
    third-generation.

    1.3.1.5) Java -> imperative, von Neumann, object-oriented, third-generation.

    1.3.1.6) Lisp -> declarative, object-oriented, functional, third-generation.

    1.3.1.7) ML -> declarative, object-oriented, functional, third-generation.

    1.3.1.8) Perl -> imperative, von Neumann, object-oriented, functional,
    third-generation, scripting.

    1.3.1.9) Python -> imperative, von Neumann, object-oriented, functional,
    third-generation, scripting.

    1.3.1.10) VB -> imperative, von Neumann, object-oriented, third-generation,
    scripting.

3. Exercises 1.6.8 on page 35:

    1.6.1) w = 13, x = 11, y = 13, z = 11.

    1.6.2) w = 9, x = 7, y = 13, z = 11.

    1.6.3) Block # -> declaration for block (scope).
    
    Block B1 -> w (B1 - B3 - B4), x (B1 - B2 - B4), y (B1 - B5), z (B1 -
    B2 - B5).

    Block B2 -> x (B2 - B3), z (B2).

    Block B3 -> w (B3), x (B3).

    Block B4 -> w (B4), x (B4).

    Block B5 -> y (B5), z (B5).

    1.6.4) The code prints:

    3

    2

=== PART 4 ===

1. Static scope: A language is said to have static scope (also known as lexical
    scope if it is possible to determine the scope of declarations by only
    looking at the program. Meaning that the location of the declaration
    determines its scope (e.g., the block it is declared under in C-like
    languages).

2. Dynamic scope: A language in which scope of declarations cannot be determined
    by only looking at the program is said to have dynamic scope. Usually this
    means that the scope is determined by time of procedure invocation rather
    than position in the code.

3. Static binding: Binding that can be decided on by the compiler at compile
    time is said to be static binding.

3. Dynamic binding: Binding that cannot be decided on by the compiler but must
    determined at run-time is said to be dynamic binding.

4. Call-by-value: In languages that use this policy, when a procedure is called
    with parameters, the actual parameter is evaluated (in the case of
    expressions) or copied (in the case of variables) and this value is placed
    in the location of the corresponding formal parameter of the procedure. This
    policy essentially has the effect of making any computations involving the
    formal parameters in the procedure local to it. Some languages mix this
    policy with other ones or have allow some way to bypass it (e.g. pointers in
    C).

5. Call-by-reference: In languages that use this policy, when a procedure is
    called with parameters, the addresses of the actual parameters are passed to
    the procedure as values for the corresponding formal parameters. Thus, any
    changes in the value of the formal parameter also takes affect on the actual
    parameter. This is the case for variables; for expressions however, a they
    are evaluated and the values are placed in a new location, therefore changes
    made to them do not affect any data in the calling unit. Call-by-reference
    is often used either as the solitary policy or for certain cases in other
    call-by-value languages. For example, when the copying the value of the
    actual parameter is judged to be too expensive (e.g., for large or aggregate
    data structures such as arrays), call-by-reference is utilized for purposes
    of efficiency.

# EOF.
